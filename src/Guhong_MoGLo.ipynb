{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_NUM = 0\n",
    "GPU_NUM = str(GPU_NUM)\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = GPU_NUM\n",
    "\n",
    "import shutil\n",
    "import warnings\n",
    "import contextlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from itertools import combinations\n",
    "from IPython.display import clear_output\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "plt.style.use('seaborn-v0_8-white')\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "\n",
    "print(torch.cuda.is_available(), ': ', torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import *\n",
    "from networks.networks import *\n",
    "from options.hyper_parameters import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = HP_Guhong(name='Guhong_MoGLo', device='cuda')\n",
    "hp.epoch_load = False\n",
    "torch.save(hp, f'../res/{hp.name}/options.pt')\n",
    "hp.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MoGLo_Net(shape=True).cuda()\n",
    "x = torch.zeros([1, 5, 1, 256, 256]).cuda()\n",
    "with torch.no_grad(): model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = Transforms_Bundle(seq=hp.seq, device=hp.device)\n",
    "train_set = Dataset_guhong(hp, phase='train', type_X=hp.type_X, type_y=hp.type_y)\n",
    "valid_set = Dataset_guhong(hp, phase='valid', type_X=hp.type_X, type_y=hp.type_y)\n",
    "train_loader = DataLoader(dataset=train_set, shuffle=True , batch_size=hp.batch_size, \n",
    "                          num_workers=4, pin_memory=True)\n",
    "valid_loader = DataLoader(dataset=valid_set, shuffle=False, batch_size=hp.batch_size, \n",
    "                          num_workers=4, pin_memory=True)\n",
    "data_loader = [train_loader, valid_loader]\n",
    "model = MoGLo_Net(dim_in=1, dim_base=hp.dim_base, c_att=True, gl_att=True)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=hp.optimizer_lr, weight_decay=1e-2)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=hp.scheduler_step, gamma=hp.scheduler_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(hp.device)\n",
    "print(f'Model: {hp.name}')\n",
    "\n",
    "# Loss & Rate(Metric)\n",
    "MME_func = MMAE(alpha=1, smooth=2)\n",
    "COR_func = Corr_loss(alpha=1)\n",
    "TRI_func = Triplet_Loss(alpha=0.005, margin=0.1, n_sample=None, dist='cos')\n",
    "MAE_func = MAE()\n",
    "\n",
    "loss = {'MME':MME_func, \n",
    "        'COR':COR_func, \n",
    "        'TRI':TRI_func}\n",
    "rate = {'MAE':MAE_func}\n",
    "\n",
    "loss_keys = ['MME', 'COR', 'TRI']\n",
    "rate_keys = ['MAE']\n",
    "\n",
    "# Continual Learning\n",
    "epoch_s, epoch_e = 1, hp.epochs+1\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "loss_epoch = torch.zeros([epoch_e, 2, len(loss_keys)])\n",
    "rate_epoch = torch.zeros([epoch_e, 2, len(rate_keys)])\n",
    "if hp.epoch_load:\n",
    "    last_point = torch.load(f'../res/{hp.name}/model/last_point.pt')\n",
    "    model.load_state_dict(last_point['model'])\n",
    "    optimizer.load_state_dict(last_point['optimizer'])\n",
    "    scaler.load_state_dict(last_point['scaler'])\n",
    "    scheduler.load_state_dict(last_point['scheduler'])\n",
    "    epoch_s = last_point['epoch']\n",
    "    history = last_point['history']\n",
    "    loss_epoch[:epoch_s] = history['loss'][:epoch_s]\n",
    "    rate_epoch[:epoch_s] = history['rate'][:epoch_s]\n",
    "    print(f'※ Continual Learning: {epoch_s-1} Epoch ※')\n",
    "\n",
    "\n",
    "# Fit\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "loss_epoch = torch.zeros([epoch_e, 2, len(loss_keys)])\n",
    "rate_epoch = torch.zeros([epoch_e, 2, len(rate_keys)])\n",
    "\n",
    "for epoch in range(epoch_s, epoch_e):\n",
    "    for i, phase in enumerate(['Train', 'Valid']):\n",
    "        if phase=='Train':\n",
    "            model.train()\n",
    "            context_manager = contextlib.nullcontext()\n",
    "        if phase=='Valid':\n",
    "            model.eval()\n",
    "            context_manager = torch.no_grad()\n",
    "        \n",
    "        loss_batch = torch.zeros([len(data_loader[i]), len(loss_keys)])\n",
    "        rate_batch = torch.zeros([len(data_loader[i]), len(rate_keys)])\n",
    "        with context_manager:\n",
    "            for k, data in enumerate(data_loader[i]):\n",
    "                B, y = data[0].to(hp.device), data[1].to(hp.device)\n",
    "                if len(B)<=1: continue\n",
    "                \n",
    "                # Forward\n",
    "                y = transforms.y_scaling(y)\n",
    "                \n",
    "                with torch.cuda.amp.autocast():\n",
    "                    p, p_emb, at_score = model(B, torch.zeros([0]))\n",
    "                    \n",
    "                    MME_res = (MME_func(p[0], y) + MME_func(p[1], y))/2\n",
    "                    COR_res = (COR_func(p[0], y) + COR_func(p[1], y))/2\n",
    "                    TRI_res = TRI_func(p_emb, y)\n",
    "                    loss_final = MME_res+COR_res+TRI_res\n",
    "                    \n",
    "                    loss_batch[k, 0] = MME_res.item()\n",
    "                    loss_batch[k, 1] = COR_res.item()\n",
    "                    loss_batch[k, 2] = TRI_res.item()\n",
    "                \n",
    "                # Backward\n",
    "                if phase=='Train':\n",
    "                    optimizer.zero_grad()\n",
    "                    scaler.scale(loss_final).backward()\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                \n",
    "                # Rate\n",
    "                with torch.no_grad():\n",
    "                    pred = transforms.y_scaling_inv(p[1])\n",
    "                    true = transforms.y_scaling_inv(y)\n",
    "                    pred[:, :, :3] *= 10\n",
    "                    true[:, :, :3] *= 10\n",
    "                    MAE_res  =  MAE_func(pred[:, -1, :], true[:, -1, :])\n",
    "\n",
    "                    rate_batch[k, 0] = MAE_res.item()\n",
    "        \n",
    "        loss_epoch[epoch, i] = torch.mean(loss_batch.cpu(), axis=0)\n",
    "        rate_epoch[epoch, i] = torch.mean(rate_batch.cpu(), axis=0)\n",
    "    \n",
    "    # Scheduler\n",
    "    if scheduler is not None: scheduler.step()\n",
    "    \n",
    "    # Monitoring\n",
    "    if epoch==1:\n",
    "        print(f'===== Loss Monitoring =====')\n",
    "        print(f'Loss: {loss_keys}', end=' ')\n",
    "        print(f'rate: {rate_keys}', end=' ')\n",
    "        print(f'(Train, Valid)')\n",
    "    if epoch%hp.monitoring_cycle==0:\n",
    "        print(f'{epoch:5.0f}/{hp.epochs:5.0f}', end=' ')\n",
    "        for l in range(len(loss_keys)):\n",
    "            loss_train = loss_epoch[epoch, 0, l]\n",
    "            loss_valid = loss_epoch[epoch, 1, l]\n",
    "            loss_ratio = (loss_train/loss_valid)*100\n",
    "            print(f'({loss_train:6.4f}, {loss_valid:6.4f})', end=f' | ')\n",
    "        print('*', end=' ')\n",
    "        for l in range(len(rate_keys)):\n",
    "            rate_train = rate_epoch[epoch, 0, l]\n",
    "            rate_valid = rate_epoch[epoch, 1, l]\n",
    "            rate_ratio = (rate_train/rate_valid)*100\n",
    "            print(f'({rate_train:6.4f}, {rate_valid:6.4f})', end=f' | ')\n",
    "        print()\n",
    "        \n",
    "        # Save\n",
    "        history = {'loss':loss_epoch, \n",
    "                   'rate':rate_epoch, \n",
    "                   'loss_keys':loss_keys, \n",
    "                   'rate_keys':rate_keys}\n",
    "        torch.save(history, f'{hp.path_model}/history.pt')\n",
    "        \n",
    "        if epoch%hp.save_cycle==0:\n",
    "            torch.save(model.state_dict(), f'{hp.path_model}/model_{epoch}.pt')\n",
    "            last_point = {'epoch':epoch, \n",
    "                          'history':history, \n",
    "                          'model':model.state_dict(), \n",
    "                          'optimizer':optimizer.state_dict(), \n",
    "                          'scaler':scaler.state_dict(), \n",
    "                          'scheduler':scheduler.state_dict()}\n",
    "            torch.save(last_point, f'{hp.path_model}/last_point.pt')\n",
    "    \n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.system(f'kill -9 {os.getpid()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
